{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Vietnamese_Chatbot_Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "b5UTsWmIOvnU",
        "iYy-6zSuOvnU"
      ]
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Xây dựng Chatbot sử dụng mô hình Transformer"
      ],
      "metadata": {
        "id": "N10v8EqGI1Ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "id": "s16yZMa6JCQt",
        "outputId": "64113f2d-1d8b-4a7b-824e-61b1def9a047",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:17.865875Z",
          "iopub.execute_input": "2022-05-22T09:41:17.866579Z",
          "iopub.status.idle": "2022-05-22T09:41:27.040374Z",
          "shell.execute_reply.started": "2022-05-22T09:41:17.866475Z",
          "shell.execute_reply": "2022-05-22T09:41:27.039557Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting underthesea\n",
            "  Downloading underthesea-1.3.4-py3-none-any.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.0.2)\n",
            "Collecting python-crfsuite>=0.9.6\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from underthesea) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from underthesea) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from underthesea) (4.64.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from underthesea) (2.23.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 56.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from underthesea) (3.2.5)\n",
            "Collecting underthesea-core==0.0.4_alpha.10\n",
            "  Downloading underthesea_core-0.0.4_alpha.10-cp37-cp37m-manylinux2010_x86_64.whl (581 kB)\n",
            "\u001b[K     |████████████████████████████████| 581 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->underthesea) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->underthesea) (2022.5.18.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->underthesea) (1.4.1)\n",
            "Installing collected packages: unidecode, underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.8 underthesea-1.3.4 underthesea-core-0.0.4a10 unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD4Cv_-kD5YX",
        "outputId": "29206b2d-2901-494a-a41f-0bd4d1e6aac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re,string\n",
        "from gensim.models import KeyedVectors\n",
        "from collections import Counter\n",
        "from underthesea import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import preprocessing, utils, activations\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BECuUXItI1o5",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:27.042377Z",
          "iopub.execute_input": "2022-05-22T09:41:27.042594Z",
          "iopub.status.idle": "2022-05-22T09:41:29.453331Z",
          "shell.execute_reply.started": "2022-05-22T09:41:27.042561Z",
          "shell.execute_reply": "2022-05-22T09:41:29.452618Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dữ liệu chatbot question-answer short style.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_Va-SWVOJLeO",
        "outputId": "b22465f1-9ad0-40b8-8952-db951d607144",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.465896Z",
          "iopub.execute_input": "2022-05-22T09:41:29.466239Z",
          "iopub.status.idle": "2022-05-22T09:41:29.500510Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.466204Z",
          "shell.execute_reply": "2022-05-22T09:41:29.499819Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                             user_a  \\\n",
              "0           0                Thích mẫu người nào   \n",
              "1           1                  Có crush ai không   \n",
              "2           2           Tại sao lại thích bạn dó   \n",
              "3           3            Có hay nói chuyện không   \n",
              "4           4  Bạn kia có bắt chuyện trước không   \n",
              "\n",
              "                             user_b  \n",
              "0      Dễ thương, tóc dài, da trắng  \n",
              "1                 Có 1 bạn cùng lớp  \n",
              "2  Vì đáp ứng những yêu cầu của tao  \n",
              "3            Hay nhắn tin messenger  \n",
              "4                        Có đôi khi  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e307e17-f83b-41b4-b52a-18eb1fc2c14c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user_a</th>\n",
              "      <th>user_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Thích mẫu người nào</td>\n",
              "      <td>Dễ thương, tóc dài, da trắng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Có crush ai không</td>\n",
              "      <td>Có 1 bạn cùng lớp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Tại sao lại thích bạn dó</td>\n",
              "      <td>Vì đáp ứng những yêu cầu của tao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Có hay nói chuyện không</td>\n",
              "      <td>Hay nhắn tin messenger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Bạn kia có bắt chuyện trước không</td>\n",
              "      <td>Có đôi khi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e307e17-f83b-41b4-b52a-18eb1fc2c14c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e307e17-f83b-41b4-b52a-18eb1fc2c14c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e307e17-f83b-41b4-b52a-18eb1fc2c14c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "7pSEtATtj5VL",
        "outputId": "81c10b98-f857-48cd-8723-e1a1897a4e6d",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.501599Z",
          "iopub.execute_input": "2022-05-22T09:41:29.501830Z",
          "iopub.status.idle": "2022-05-22T09:41:29.507579Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.501799Z",
          "shell.execute_reply": "2022-05-22T09:41:29.506704Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5900, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Cleaning / Preprocessing**"
      ],
      "metadata": {
        "id": "WHl7tRh9lO9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "UkcfrZNKlm9i",
        "outputId": "873c8934-260b-499d-8aab-fd479fc9fb1b",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.508974Z",
          "iopub.execute_input": "2022-05-22T09:41:29.509216Z",
          "iopub.status.idle": "2022-05-22T09:41:29.520237Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.509183Z",
          "shell.execute_reply": "2022-05-22T09:41:29.519341Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "user_a        0\n",
              "user_b        1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = df[df['user_b'].isnull()].index.tolist() # Get index of nan row\n",
        "print('Question of nan answer: ' ,df['user_a'][idx].values)"
      ],
      "metadata": {
        "id": "6rEQUmGqhPJY",
        "outputId": "c3d8ba88-1fed-44a6-dbe9-4bcc46fe5cbc",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.521638Z",
          "iopub.execute_input": "2022-05-22T09:41:29.522736Z",
          "iopub.status.idle": "2022-05-22T09:41:29.533250Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.522702Z",
          "shell.execute_reply": "2022-05-22T09:41:29.532376Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question of nan answer:  ['Anh chị em làm gì?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in nan row value\n",
        "df['user_b'] = df['user_b'].fillna('Luật sư').values "
      ],
      "metadata": {
        "id": "shyshZ51lsWG",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.534772Z",
          "iopub.execute_input": "2022-05-22T09:41:29.536479Z",
          "iopub.status.idle": "2022-05-22T09:41:29.543966Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.536440Z",
          "shell.execute_reply": "2022-05-22T09:41:29.543001Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "EMOTICONS = { \n",
        "    u\":-3\":\"Happy face smiley\",\n",
        "    u\":3\":\"Happy face smiley\",\n",
        "    u\":->\":\"Happy face smiley\",\n",
        "    u\":>\":\"Happy face smiley\",\n",
        "    u\":))\":\"Happy face smiley\",\n",
        "    u\":)))\":\"Happy face smiley\",\n",
        "    u\":))))\":\"Happy face smiley\",\n",
        "    u\":'<\":\"Happy face smiley\",\n",
        "    u\":)\":\"Happy face smiley\",\n",
        "    u\":(\":\"Happy face smiley\",\n",
        "    u\":((\":\"Happy face smiley\",\n",
        "    u\":‑D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
        "    u\":‑c\":\"Frown, sad, andry or pouting\",\n",
        "    u\":c\":\"Frown, sad, andry or pouting\",\n",
        "    u\":‑<\":\"Frown, sad, andry or pouting\",\n",
        "    u\":<\":\"Frown, sad, andry or pouting\",\n",
        "    u\":@\":\"Frown, sad, andry or pouting\",\n",
        "    u\"D:\":\"Sadness\",\n",
        "    u\":O\":\"Surprise\",\n",
        "    u\":o\":\"Surprise\",\n",
        "}\n",
        "\n",
        "cnt = Counter()\n",
        "for text in df[\"user_b\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1\n",
        "\n",
        "RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-10-1:-1]]) #Get top 10 rare word\n",
        "\n",
        "def remove_emoticons(text):\n",
        "    \"Function to remove emoticons\"\n",
        "    arr = [word for word in text.split() if word not in EMOTICONS.keys()]\n",
        "    return \" \".join(arr)\n",
        "\n",
        "def remove_rarewords(text):\n",
        "    \"\"\"custom function to remove the rare words\"\"\"\n",
        "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n",
        "\n",
        "def preprocessing(df): \n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation))) # Remove punctuation\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: ele.translate(str.maketrans('', '', string.punctuation))) \n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: remove_emoticons(ele)) # Remove emoticons\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: remove_emoticons(ele))\n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: remove_rarewords(ele)) # Remove rarewords\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: remove_rarewords(ele))\n",
        "  df['user_b'] = df['user_b'].apply(lambda ele: 'START ' + ele + ' END')\n",
        "  df[\"user_a\"] = df[\"user_a\"].apply(lambda ele: ele.lower()) # convert text to lowercase\n",
        "  df[\"user_b\"] = df[\"user_b\"].apply(lambda ele: ele.lower()) \n",
        "  \n",
        "  return df\n",
        "\n",
        "df = preprocessing(df)"
      ],
      "metadata": {
        "id": "hYVnIqkEJTTj",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.545822Z",
          "iopub.execute_input": "2022-05-22T09:41:29.546458Z",
          "iopub.status.idle": "2022-05-22T09:41:29.686327Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.546418Z",
          "shell.execute_reply": "2022-05-22T09:41:29.685597Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = df.values #numpy \n",
        "questions = data[:,1] # convert question to a list\n",
        "answers = data[:,2] # convert answer that match with question to list\n",
        "print(questions[:5]) \n",
        "print(answers[:5])"
      ],
      "metadata": {
        "id": "hHcACgVuJWQf",
        "outputId": "f85157ea-71fe-484a-bd03-9156c46a196b",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.689142Z",
          "iopub.execute_input": "2022-05-22T09:41:29.689382Z",
          "iopub.status.idle": "2022-05-22T09:41:29.696244Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.689349Z",
          "shell.execute_reply": "2022-05-22T09:41:29.695265Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thích mẫu người nào' 'có crush ai không' 'tại sao lại thích bạn dó'\n",
            " 'có hay nói chuyện không' 'bạn kia có bắt chuyện trước không']\n",
            "['start dễ thương tóc dài da trắng end' 'start có 1 bạn cùng lớp end'\n",
            " 'start vì đáp ứng những yêu cầu của tao end'\n",
            " 'start hay nhắn tin messenger end' 'start có đôi khi end']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization and Encode, Decode**"
      ],
      "metadata": {
        "id": "3GalJfC-yhwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization questions\n",
        "questions = [word_tokenize(ques) for ques in questions]\n",
        "print(len(questions))\n",
        "print(questions[:3])"
      ],
      "metadata": {
        "id": "tM0OEAcmJZZY",
        "outputId": "ff6a9fc0-dcf9-441b-ae40-6f5001f4146f",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:29.697738Z",
          "iopub.execute_input": "2022-05-22T09:41:29.698267Z",
          "iopub.status.idle": "2022-05-22T09:41:31.041805Z",
          "shell.execute_reply.started": "2022-05-22T09:41:29.698226Z",
          "shell.execute_reply": "2022-05-22T09:41:31.041015Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5900\n",
            "[['thích', 'mẫu', 'người', 'nào'], ['có', 'crush', 'ai', 'không'], ['tại sao', 'lại', 'thích', 'bạn', 'dó']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization answer\n",
        "answers = [word_tokenize(ans) for ans in answers]\n",
        "print(len(answers))\n",
        "print(answers[:3])"
      ],
      "metadata": {
        "id": "axGM_AzyKMP-",
        "outputId": "1f00bd49-baa1-4689-bb0b-4c6adcf8beab",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:31.043183Z",
          "iopub.execute_input": "2022-05-22T09:41:31.043525Z",
          "iopub.status.idle": "2022-05-22T09:41:32.435404Z",
          "shell.execute_reply.started": "2022-05-22T09:41:31.043479Z",
          "shell.execute_reply": "2022-05-22T09:41:32.434593Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5900\n",
            "[['start', 'dễ thương', 'tóc', 'dài', 'da', 'trắng', 'end'], ['start', 'có', '1', 'bạn', 'cùng', 'lớp', 'end'], ['start', 'vì', 'đáp ứng', 'những', 'yêu cầu', 'của', 'tao', 'end']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 2\n",
        "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))"
      ],
      "metadata": {
        "id": "QsR71gvjKC1-",
        "outputId": "7f03ed2c-60f5-4e75-bf6d-4a17451f7126",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:32.436597Z",
          "iopub.execute_input": "2022-05-22T09:41:32.437276Z",
          "iopub.status.idle": "2022-05-22T09:41:32.503574Z",
          "shell.execute_reply.started": "2022-05-22T09:41:32.437237Z",
          "shell.execute_reply": "2022-05-22T09:41:32.502862Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VOCAB SIZE : 3645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx = tokenizer.word_index"
      ],
      "metadata": {
        "id": "xRrlh0_NLe5g",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:32.504869Z",
          "iopub.execute_input": "2022-05-22T09:41:32.505118Z",
          "iopub.status.idle": "2022-05-22T09:41:32.509332Z",
          "shell.execute_reply.started": "2022-05-22T09:41:32.505085Z",
          "shell.execute_reply": "2022-05-22T09:41:32.508228Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoder_input_data\n",
        "tokenized_questions = tokenizer.texts_to_sequences(questions)\n",
        "maxlen_questions = max([len(x) for x in tokenized_questions])\n",
        "padded_questions = pad_sequences(tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
        "encoder_input_data = np.array(padded_questions)\n",
        "print(\"Max length question:\", maxlen_questions)\n",
        "print(encoder_input_data.shape)"
      ],
      "metadata": {
        "id": "LRbibHDuKqY0",
        "outputId": "f28109f3-234b-49db-ba08-e2adbebd203b",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:32.511088Z",
          "iopub.execute_input": "2022-05-22T09:41:32.511356Z",
          "iopub.status.idle": "2022-05-22T09:41:32.564318Z",
          "shell.execute_reply.started": "2022-05-22T09:41:32.511322Z",
          "shell.execute_reply": "2022-05-22T09:41:32.563662Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length question: 76\n",
            "(5900, 76)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_input_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "maxlen_answers = max([len(x) for x in tokenized_answers])\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding='post')\n",
        "decoder_input_data = np.array(padded_answers)\n",
        "print(\"Max length anwser:\", maxlen_answers)\n",
        "print(decoder_input_data.shape)"
      ],
      "metadata": {
        "id": "FSuEOE4rLCzo",
        "outputId": "a8dd5b93-985e-4b51-a26e-dd9088cc1e8d",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:32.566258Z",
          "iopub.execute_input": "2022-05-22T09:41:32.566690Z",
          "iopub.status.idle": "2022-05-22T09:41:32.617942Z",
          "shell.execute_reply.started": "2022-05-22T09:41:32.566656Z",
          "shell.execute_reply": "2022-05-22T09:41:32.617234Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length anwser: 43\n",
            "(5900, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decoder_output_data\n",
        "tokenized_answers = tokenizer.texts_to_sequences(answers)\n",
        "# Remove Start added before\n",
        "for i in range(len(tokenized_answers)):\n",
        "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
        "padded_answers = pad_sequences(tokenized_answers, maxlen = maxlen_answers, padding='post')\n",
        "#onehot_answers = tf.keras.utils.to_categorical(padded_answers, VOCAB_SIZE)\n",
        "decoder_output_data = np.array(padded_answers)\n",
        "print(decoder_output_data.shape)"
      ],
      "metadata": {
        "id": "AEHXML0aLRx9",
        "outputId": "509575b4-c36e-4623-baa9-304c94d305c2",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:32.619183Z",
          "iopub.execute_input": "2022-05-22T09:41:32.619430Z",
          "iopub.status.idle": "2022-05-22T09:41:32.670244Z",
          "shell.execute_reply.started": "2022-05-22T09:41:32.619399Z",
          "shell.execute_reply": "2022-05-22T09:41:32.669534Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5900, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word2Vec Embedding with FastText**"
      ],
      "metadata": {
        "id": "XIRPpLBYyhwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/wiki.vi.vec')\n",
        "print(\"FastText Loaded!\")"
      ],
      "metadata": {
        "id": "cu2AjHISyhwG",
        "outputId": "58870efe-390d-498e-b13b-c5b5e3f61fbb",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:41:32.671526Z",
          "iopub.execute_input": "2022-05-22T09:41:32.671766Z",
          "iopub.status.idle": "2022-05-22T09:42:31.583393Z",
          "shell.execute_reply.started": "2022-05-22T09:41:32.671734Z",
          "shell.execute_reply": "2022-05-22T09:42:31.582597Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText Loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_dim = 300\n",
        "\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, embeddings_dim))\n",
        "\n",
        "for word, index in word2idx.items():\n",
        "    try:\n",
        "        embedding_matrix[index,:] = fastText_model[word]\n",
        "    except:\n",
        "        continue\n",
        "        \n",
        "print(embedding_matrix.shape)"
      ],
      "metadata": {
        "id": "aqRqb_KYyhwG",
        "outputId": "28191f15-c0e0-4bcc-e8b8-7a82e96d88b5",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.584559Z",
          "iopub.execute_input": "2022-05-22T09:42:31.585362Z",
          "iopub.status.idle": "2022-05-22T09:42:31.608955Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.585318Z",
          "shell.execute_reply": "2022-05-22T09:42:31.608304Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3645, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Structure"
      ],
      "metadata": {
        "id": "b5UTsWmIOvnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://quantdare.com/wp-content/uploads/2021/11/transformer_arch.png)"
      ],
      "metadata": {
        "id": "rOdcquHvOvnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ta có thể thấy lớp Encoder gồm N khối (ta tạm gọi là EncoderLayer). Và đầu ra của N khối này sẽ được nối sang bên Decoder. Tương tự với đó là bên Decoder cũng chứa N khối DecoderLayer. "
      ],
      "metadata": {
        "id": "MO-sRWXJOvnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder:\n",
        "- Gồm lớp Embedding, Positional Encoding và các lớp Encoder \n",
        "## Lớp Encoder:\n",
        "- Gồm lớp Multi-Head Attention, 2 lớp Add & Norm và 1 mạng Feed Forward\n",
        "\n",
        "### Decoder:\n",
        "- Gồm lớp Embedding, Positional Encoding và các lớp Decoder \n",
        "## Lớp Encoder:\n",
        "- Gồm lớp 3 khối:\n",
        " + Masked Multi-Head Attention, 1 lớp Add & Norm \n",
        " + Multi-Head Attention nhận 2 ma trận K,V từ lớp encoder, 1 lớp Add & Norm \n",
        " + 1 mạng Feed Forward và 1 lớp Add & Norm \n",
        " \n",
        "### Đi qua một mạng Linear và Softmax để có được output"
      ],
      "metadata": {
        "id": "iYy-6zSuOvnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Defination"
      ],
      "metadata": {
        "id": "GMCTx2fdyhwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attension** "
      ],
      "metadata": {
        "id": "wy83DBG7OvnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.609981Z",
          "iopub.execute_input": "2022-05-22T09:42:31.610444Z",
          "iopub.status.idle": "2022-05-22T09:42:31.617862Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.610401Z",
          "shell.execute_reply": "2022-05-22T09:42:31.616979Z"
        },
        "trusted": true,
        "id": "FF2cZ0V6OvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.619289Z",
          "iopub.execute_input": "2022-05-22T09:42:31.620059Z",
          "iopub.status.idle": "2022-05-22T09:42:31.639151Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.620023Z",
          "shell.execute_reply": "2022-05-22T09:42:31.638425Z"
        },
        "trusted": true,
        "id": "XGuf6iI_OvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Masking**"
      ],
      "metadata": {
        "id": "QyjffpOIOvnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.640336Z",
          "iopub.execute_input": "2022-05-22T09:42:31.641018Z",
          "iopub.status.idle": "2022-05-22T09:42:31.651748Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.640976Z",
          "shell.execute_reply": "2022-05-22T09:42:31.650897Z"
        },
        "trusted": true,
        "id": "cn3YNpruOvnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.653166Z",
          "iopub.execute_input": "2022-05-22T09:42:31.653917Z",
          "iopub.status.idle": "2022-05-22T09:42:31.660981Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.653881Z",
          "shell.execute_reply": "2022-05-22T09:42:31.660119Z"
        },
        "trusted": true,
        "id": "nGbSQ4VbOvnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional Encoding**"
      ],
      "metadata": {
        "id": "aqb-6PNiOvnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.662305Z",
          "iopub.execute_input": "2022-05-22T09:42:31.663010Z",
          "iopub.status.idle": "2022-05-22T09:42:31.674377Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.662972Z",
          "shell.execute_reply": "2022-05-22T09:42:31.673585Z"
        },
        "trusted": true,
        "id": "R7gtwfSJOvnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder Layer**"
      ],
      "metadata": {
        "id": "8Fl6CtWkOvnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.675699Z",
          "iopub.execute_input": "2022-05-22T09:42:31.676470Z",
          "iopub.status.idle": "2022-05-22T09:42:31.687709Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.676423Z",
          "shell.execute_reply": "2022-05-22T09:42:31.686849Z"
        },
        "trusted": true,
        "id": "B6u40whoOvnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder**"
      ],
      "metadata": {
        "id": "Qyt6bkxNOvnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size,d_model\n",
        "                                     ,input_length=maxlen_questions\n",
        "                                     ,weights = [embedding_matrix]\n",
        "                                     ,trainable=False)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.690458Z",
          "iopub.execute_input": "2022-05-22T09:42:31.692412Z",
          "iopub.status.idle": "2022-05-22T09:42:31.701633Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.692383Z",
          "shell.execute_reply": "2022-05-22T09:42:31.700711Z"
        },
        "trusted": true,
        "id": "CKDB7_4BOvnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder Layer**"
      ],
      "metadata": {
        "id": "YjCC7og9OvnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.702976Z",
          "iopub.execute_input": "2022-05-22T09:42:31.703401Z",
          "iopub.status.idle": "2022-05-22T09:42:31.716242Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.703365Z",
          "shell.execute_reply": "2022-05-22T09:42:31.715491Z"
        },
        "trusted": true,
        "id": "0m5zRdw9OvnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder**"
      ],
      "metadata": {
        "id": "L79WxqzkOvnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size,d_model\n",
        "                                     ,input_length=maxlen_answers\n",
        "                                     ,weights = [embedding_matrix]\n",
        "                                     ,trainable=False)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.721071Z",
          "iopub.execute_input": "2022-05-22T09:42:31.721286Z",
          "iopub.status.idle": "2022-05-22T09:42:31.732587Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.721260Z",
          "shell.execute_reply": "2022-05-22T09:42:31.731876Z"
        },
        "trusted": true,
        "id": "8lwz2HZbOvnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformer**"
      ],
      "metadata": {
        "id": "BA5cJywUOvnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size)(dec_outputs)\n",
        "  #Add a softmax layer to get probability distribution of word in vocab\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, activation = 'softmax',name = \"outputs\")(outputs)\n",
        "\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.734658Z",
          "iopub.execute_input": "2022-05-22T09:42:31.735178Z",
          "iopub.status.idle": "2022-05-22T09:42:31.747257Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.735141Z",
          "shell.execute_reply": "2022-05-22T09:42:31.746519Z"
        },
        "trusted": true,
        "id": "mcnMVf7pOvnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "NUM_HEADS = 6 # model dims must divided to number of heads\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.748556Z",
          "iopub.execute_input": "2022-05-22T09:42:31.749001Z",
          "iopub.status.idle": "2022-05-22T09:42:31.764062Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.748964Z",
          "shell.execute_reply": "2022-05-22T09:42:31.763233Z"
        },
        "trusted": true,
        "id": "jMjtWEI0OvnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=embeddings_dim,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:31.766261Z",
          "iopub.execute_input": "2022-05-22T09:42:31.766795Z",
          "iopub.status.idle": "2022-05-22T09:42:35.103972Z",
          "shell.execute_reply.started": "2022-05-22T09:42:31.766733Z",
          "shell.execute_reply": "2022-05-22T09:42:35.103252Z"
        },
        "trusted": true,
        "id": "NVxpPed0OvnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.105250Z",
          "iopub.execute_input": "2022-05-22T09:42:35.105516Z",
          "iopub.status.idle": "2022-05-22T09:42:35.121019Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.105482Z",
          "shell.execute_reply": "2022-05-22T09:42:35.120342Z"
        },
        "trusted": true,
        "id": "MLTgeQcyOvnY",
        "outputId": "fd5bfe2f-1225-45e8-f00c-4de0fa348f41"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"transformer\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninputs (InputLayer)             [(None, None)]       0                                            \n__________________________________________________________________________________________________\ndec_inputs (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\nenc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n__________________________________________________________________________________________________\nencoder (Functional)            (None, None, 300)    2434324     inputs[0][0]                     \n                                                                 enc_padding_mask[0][0]           \n__________________________________________________________________________________________________\nlook_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n__________________________________________________________________________________________________\ndec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n__________________________________________________________________________________________________\ndecoder (Functional)            (None, None, 300)    3157924     dec_inputs[0][0]                 \n                                                                 encoder[0][0]                    \n                                                                 look_ahead_mask[0][0]            \n                                                                 dec_padding_mask[0][0]           \n__________________________________________________________________________________________________\ndense_32 (Dense)                (None, None, 3645)   1097145     decoder[0][0]                    \n__________________________________________________________________________________________________\noutputs (Dense)                 (None, None, 3645)   13289670    dense_32[0][0]                   \n==================================================================================================\nTotal params: 19,979,063\nTrainable params: 17,792,063\nNon-trainable params: 2,187,000\n__________________________________________________________________________________________________\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Loss Function** "
      ],
      "metadata": {
        "id": "FHuw_J4AOvnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, maxlen_answers))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.122282Z",
          "iopub.execute_input": "2022-05-22T09:42:35.122559Z",
          "iopub.status.idle": "2022-05-22T09:42:35.128212Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.122522Z",
          "shell.execute_reply": "2022-05-22T09:42:35.127290Z"
        },
        "trusted": true,
        "id": "c14R7vrBOvnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer with custom learning rate**"
      ],
      "metadata": {
        "id": "49SXEoVnOvnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=2000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.129519Z",
          "iopub.execute_input": "2022-05-22T09:42:35.130015Z",
          "iopub.status.idle": "2022-05-22T09:42:35.140240Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.129977Z",
          "shell.execute_reply": "2022-05-22T09:42:35.139555Z"
        },
        "trusted": true,
        "id": "1OD5gN7gOvnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(embeddings_dim)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.142596Z",
          "iopub.execute_input": "2022-05-22T09:42:35.143040Z",
          "iopub.status.idle": "2022-05-22T09:42:35.149751Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.143007Z",
          "shell.execute_reply": "2022-05-22T09:42:35.148990Z"
        },
        "trusted": true,
        "id": "JkZ0i6FWOvnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compile the model**"
      ],
      "metadata": {
        "id": "6icgs0QFOvnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, maxlen_answers))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.150823Z",
          "iopub.execute_input": "2022-05-22T09:42:35.151649Z",
          "iopub.status.idle": "2022-05-22T09:42:35.158604Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.151548Z",
          "shell.execute_reply": "2022-05-22T09:42:35.157716Z"
        },
        "trusted": true,
        "id": "cnVSKizKOvnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.159807Z",
          "iopub.execute_input": "2022-05-22T09:42:35.160599Z",
          "iopub.status.idle": "2022-05-22T09:42:35.177569Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.160562Z",
          "shell.execute_reply": "2022-05-22T09:42:35.176839Z"
        },
        "trusted": true,
        "id": "d8smGcpvOvna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=64, epochs=100)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:42:35.180646Z",
          "iopub.execute_input": "2022-05-22T09:42:35.181289Z",
          "iopub.status.idle": "2022-05-22T09:57:02.718178Z",
          "shell.execute_reply.started": "2022-05-22T09:42:35.181258Z",
          "shell.execute_reply": "2022-05-22T09:57:02.717459Z"
        },
        "trusted": true,
        "id": "VSr9MCVQOvna",
        "outputId": "ed755034-7c88-4243-cb4f-d9e8a5d463b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-05-22 09:42:35.226073: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "93/93 [==============================] - 14s 87ms/step - loss: 0.5806 - accuracy: 0.0191\nEpoch 2/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.4671 - accuracy: 0.0250\nEpoch 3/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.4292 - accuracy: 0.0265\nEpoch 4/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.3888 - accuracy: 0.0275\nEpoch 5/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.3530 - accuracy: 0.0288\nEpoch 6/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.3212 - accuracy: 0.0303\nEpoch 7/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.2939 - accuracy: 0.0316\nEpoch 8/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.2712 - accuracy: 0.0336\nEpoch 9/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.2526 - accuracy: 0.0356\nEpoch 10/100\n93/93 [==============================] - 8s 89ms/step - loss: 0.2396 - accuracy: 0.0369\nEpoch 11/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.2252 - accuracy: 0.0387\nEpoch 12/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.2154 - accuracy: 0.0405\nEpoch 13/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.2110 - accuracy: 0.0409\nEpoch 14/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.2080 - accuracy: 0.0417\nEpoch 15/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1998 - accuracy: 0.0428\nEpoch 16/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.2007 - accuracy: 0.0428\nEpoch 17/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.1953 - accuracy: 0.0439\nEpoch 18/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1905 - accuracy: 0.0447\nEpoch 19/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1919 - accuracy: 0.0444\nEpoch 20/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1883 - accuracy: 0.0448\nEpoch 21/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.1887 - accuracy: 0.0449\nEpoch 22/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1841 - accuracy: 0.0457\nEpoch 23/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1761 - accuracy: 0.0473\nEpoch 24/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1689 - accuracy: 0.0483\nEpoch 25/100\n93/93 [==============================] - 8s 89ms/step - loss: 0.1560 - accuracy: 0.0503\nEpoch 26/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1498 - accuracy: 0.0517\nEpoch 27/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1401 - accuracy: 0.0532\nEpoch 28/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1354 - accuracy: 0.0545\nEpoch 29/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.1264 - accuracy: 0.0563\nEpoch 30/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1230 - accuracy: 0.0570\nEpoch 31/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1150 - accuracy: 0.0584\nEpoch 32/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.1121 - accuracy: 0.0588\nEpoch 33/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.1073 - accuracy: 0.0602\nEpoch 34/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.1013 - accuracy: 0.0619\nEpoch 35/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0995 - accuracy: 0.0619\nEpoch 36/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0962 - accuracy: 0.0632\nEpoch 37/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0901 - accuracy: 0.0643\nEpoch 38/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0899 - accuracy: 0.0644\nEpoch 39/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0865 - accuracy: 0.0650\nEpoch 40/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0831 - accuracy: 0.0659\nEpoch 41/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0811 - accuracy: 0.0663\nEpoch 42/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0796 - accuracy: 0.0669\nEpoch 43/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0764 - accuracy: 0.0675\nEpoch 44/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0757 - accuracy: 0.0678\nEpoch 45/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0722 - accuracy: 0.0688\nEpoch 46/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0724 - accuracy: 0.0687\nEpoch 47/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0683 - accuracy: 0.0697\nEpoch 48/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0695 - accuracy: 0.0696\nEpoch 49/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0679 - accuracy: 0.0696\nEpoch 50/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0657 - accuracy: 0.0703\nEpoch 51/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0645 - accuracy: 0.0708\nEpoch 52/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0634 - accuracy: 0.0708\nEpoch 53/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0619 - accuracy: 0.0712\nEpoch 54/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0611 - accuracy: 0.0714\nEpoch 55/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0590 - accuracy: 0.0720\nEpoch 56/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0585 - accuracy: 0.0721\nEpoch 57/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0575 - accuracy: 0.0725\nEpoch 58/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0576 - accuracy: 0.0725\nEpoch 59/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0566 - accuracy: 0.0727\nEpoch 60/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0552 - accuracy: 0.0729\nEpoch 61/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0546 - accuracy: 0.0731\nEpoch 62/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0530 - accuracy: 0.0737\nEpoch 63/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0529 - accuracy: 0.0736\nEpoch 64/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0524 - accuracy: 0.0737\nEpoch 65/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0516 - accuracy: 0.0738\nEpoch 66/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0504 - accuracy: 0.0742\nEpoch 67/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0500 - accuracy: 0.0743\nEpoch 68/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0487 - accuracy: 0.0747\nEpoch 69/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0498 - accuracy: 0.0744\nEpoch 70/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0494 - accuracy: 0.0743\nEpoch 71/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0473 - accuracy: 0.0751\nEpoch 72/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0466 - accuracy: 0.0750\nEpoch 73/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0464 - accuracy: 0.0751\nEpoch 74/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0455 - accuracy: 0.0754\nEpoch 75/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0462 - accuracy: 0.0753\nEpoch 76/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0444 - accuracy: 0.0758\nEpoch 77/100\n93/93 [==============================] - 8s 89ms/step - loss: 0.0443 - accuracy: 0.0759\nEpoch 78/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0453 - accuracy: 0.0754\nEpoch 79/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0437 - accuracy: 0.0757\nEpoch 80/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0437 - accuracy: 0.0759\nEpoch 81/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0427 - accuracy: 0.0761\nEpoch 82/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0429 - accuracy: 0.0758\nEpoch 83/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0432 - accuracy: 0.0758\nEpoch 84/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0427 - accuracy: 0.0760\nEpoch 85/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0423 - accuracy: 0.0762\nEpoch 86/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0409 - accuracy: 0.0765\nEpoch 87/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0409 - accuracy: 0.0765\nEpoch 88/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0406 - accuracy: 0.0765\nEpoch 89/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0403 - accuracy: 0.0766\nEpoch 90/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0396 - accuracy: 0.0769\nEpoch 91/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0401 - accuracy: 0.0768\nEpoch 92/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0390 - accuracy: 0.0771\nEpoch 93/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0402 - accuracy: 0.0766\nEpoch 94/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0387 - accuracy: 0.0769\nEpoch 95/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0387 - accuracy: 0.0768\nEpoch 96/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0390 - accuracy: 0.0770\nEpoch 97/100\n93/93 [==============================] - 8s 88ms/step - loss: 0.0391 - accuracy: 0.0769\nEpoch 98/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0377 - accuracy: 0.0772\nEpoch 99/100\n93/93 [==============================] - 8s 86ms/step - loss: 0.0376 - accuracy: 0.0772\nEpoch 100/100\n93/93 [==============================] - 8s 87ms/step - loss: 0.0377 - accuracy: 0.0771\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize Training Progress**"
      ],
      "metadata": {
        "id": "eH1yQPSRyhwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'],label='Training_loss')\n",
        "plt.legend()\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "plt.savefig('Loss_Graph')"
      ],
      "metadata": {
        "id": "w4JcHuaJyhwH",
        "outputId": "ad205e9f-48b2-4b8a-d63c-6ed925138379",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:57:02.719925Z",
          "iopub.execute_input": "2022-05-22T09:57:02.720232Z",
          "iopub.status.idle": "2022-05-22T09:57:02.916747Z",
          "shell.execute_reply.started": "2022-05-22T09:57:02.720193Z",
          "shell.execute_reply": "2022-05-22T09:57:02.916127Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 0 Axes>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('chatbot_weights.h5')"
      ],
      "metadata": {
        "id": "Wt1s-hbuyhwH",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:57:02.917949Z",
          "iopub.execute_input": "2022-05-22T09:57:02.918176Z",
          "iopub.status.idle": "2022-05-22T09:57:03.187027Z",
          "shell.execute_reply.started": "2022-05-22T09:57:02.918144Z",
          "shell.execute_reply": "2022-05-22T09:57:03.186130Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bot Chatting**"
      ],
      "metadata": {
        "id": "G2eRhxJTyhwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/chatbotTrans_weights.h5')"
      ],
      "metadata": {
        "id": "wZI3YRphFTQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2word = tokenizer.index_word"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:57:03.189185Z",
          "iopub.execute_input": "2022-05-22T09:57:03.189461Z",
          "iopub.status.idle": "2022-05-22T09:57:03.193647Z",
          "shell.execute_reply.started": "2022-05-22T09:57:03.189425Z",
          "shell.execute_reply": "2022-05-22T09:57:03.192924Z"
        },
        "trusted": true,
        "id": "yCxXjPcxOvnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_tokens(sentence):\n",
        "    words = word_tokenize(sentence.lower())\n",
        "    tokens_list = []\n",
        "    \n",
        "    for word in words:\n",
        "        tokens_list.append(word2idx[word]) \n",
        "    return pad_sequences([tokens_list],maxlen = maxlen_questions , padding='post')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:57:03.195054Z",
          "iopub.execute_input": "2022-05-22T09:57:03.195993Z",
          "iopub.status.idle": "2022-05-22T09:57:03.203336Z",
          "shell.execute_reply.started": "2022-05-22T09:57:03.195951Z",
          "shell.execute_reply": "2022-05-22T09:57:03.202562Z"
        },
        "trusted": true,
        "id": "H2c1RprTOvnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "  sentence = str_to_tokens(sentence)\n",
        "  output = np.zeros((1, 1))\n",
        "  output[0, 0] = word2idx['start']\n",
        "\n",
        "  for i in range(maxlen_answers):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, word2idx['end']):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "    \n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = \" \".join(idx2word[tf.get_static_value(i)] for i in prediction if i < VOCAB_SIZE)\n",
        "  return predicted_sentence.replace(\"start\",\"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-05-22T09:57:03.204527Z",
          "iopub.execute_input": "2022-05-22T09:57:03.204905Z",
          "iopub.status.idle": "2022-05-22T09:57:03.215169Z",
          "shell.execute_reply.started": "2022-05-22T09:57:03.204869Z",
          "shell.execute_reply": "2022-05-22T09:57:03.214525Z"
        },
        "trusted": true,
        "id": "K2LVyvWhOvnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag=True\n",
        "print(\"BOT: Xin chào! Tôi là ChatBot. Nếu bạn muốn ngưng cuộc trò chuyện, hãy gõ Bye!\")\n",
        "\n",
        "while(flag==True):\n",
        "    human_response = input('Enter question : ')\n",
        "    if human_response != 'bye':\n",
        "        try:\n",
        "            print('BOT: ' + predict(human_response))\n",
        "        except:\n",
        "            print(\"BOT: Xin lỗi câu này tôi chưa đc học ,vui lòng hỏi lại :( \")\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"BOT: Tạm biệt nha!\")"
      ],
      "metadata": {
        "id": "mjaicXTBUBC7",
        "outputId": "70323b5d-d25d-4d52-eb89-9c9af4c702a4",
        "execution": {
          "iopub.status.busy": "2022-05-22T09:57:03.216413Z",
          "iopub.execute_input": "2022-05-22T09:57:03.216655Z",
          "iopub.status.idle": "2022-05-22T10:01:33.349745Z",
          "shell.execute_reply.started": "2022-05-22T09:57:03.216622Z",
          "shell.execute_reply": "2022-05-22T10:01:33.348881Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOT: Xin chào! Tôi là ChatBot. Nếu bạn muốn ngưng cuộc trò chuyện, hãy gõ Bye!\n",
            "Enter question : người yêu bạn tên gì\n",
            "BOT:  nguyệt\n",
            "Enter question : người yêu bạn học ở trường nào\n",
            "BOT:  mình học trường tôn đức thắng\n",
            "Enter question : bạn đang học ngành gì\n",
            "BOT:  kế toán\n",
            "Enter question : bạn có anh chị em không\n",
            "BOT:  mình có chị thôi\n",
            "Enter question : nhà bạn có bao nhiêu người\n",
            "BOT:  1111 số người trong nhà\n",
            "Enter question : mẹ bạn làm gì\n",
            "BOT:  làm hành gia\n",
            "Enter question : bye\n",
            "BOT: Tạm biệt nha!\n"
          ]
        }
      ]
    }
  ]
}